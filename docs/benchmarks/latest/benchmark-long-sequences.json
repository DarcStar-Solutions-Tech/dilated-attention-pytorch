{
  "metadata": {
    "timestamp": "2025-06-27-1018-UTC",
    "device": "NVIDIA GeForce GTX 1080",
    "total_memory_gb": 7.8841552734375,
    "dtype": "float16",
    "num_heads": 8,
    "head_dim": 64
  },
  "results": {
    "ImprovedDilatedAttention": [
      {
        "implementation": "ImprovedDilatedAttention",
        "seq_len": 32768,
        "batch_size": 4,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 1307.5578960900505,
        "std_time_ms": 90.30748131621463,
        "peak_memory_mb": 688.0625,
        "memory_per_token": 0.005249500274658203,
        "throughput_tokens_per_sec": 100241.83280292255,
        "success": true,
        "error": null
      },
      {
        "implementation": "ImprovedDilatedAttention",
        "seq_len": 65536,
        "batch_size": 2,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 1553.9273312315345,
        "std_time_ms": 138.17383577473356,
        "peak_memory_mb": 696.25,
        "memory_per_token": 0.0053119659423828125,
        "throughput_tokens_per_sec": 84348.86070001837,
        "success": true,
        "error": null
      },
      {
        "implementation": "ImprovedDilatedAttention",
        "seq_len": 131072,
        "batch_size": 1,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 1837.7244357640545,
        "std_time_ms": 333.32396813704094,
        "peak_memory_mb": 696.375,
        "memory_per_token": 0.005312919616699219,
        "throughput_tokens_per_sec": 71322.989153978,
        "success": true,
        "error": null
      }
    ],
    "ImprovedMultiheadDilatedAttention": [
      {
        "implementation": "ImprovedMultiheadDilatedAttention",
        "seq_len": 32768,
        "batch_size": 4,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 4116.939522946875,
        "std_time_ms": 133.1348524520806,
        "peak_memory_mb": 1850.1953125,
        "memory_per_token": 0.014115869998931885,
        "throughput_tokens_per_sec": 31837.24202637294,
        "success": true,
        "error": null
      },
      {
        "implementation": "ImprovedMultiheadDilatedAttention",
        "seq_len": 65536,
        "batch_size": 2,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 3937.2624714548388,
        "std_time_ms": 178.90744195616153,
        "peak_memory_mb": 1850.2578125,
        "memory_per_token": 0.014116346836090088,
        "throughput_tokens_per_sec": 33290.135201874975,
        "success": true,
        "error": null
      },
      {
        "implementation": "ImprovedMultiheadDilatedAttention",
        "seq_len": 131072,
        "batch_size": 1,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 4465.259291231632,
        "std_time_ms": 353.4379327522053,
        "peak_memory_mb": 1850.3828125,
        "memory_per_token": 0.014117300510406494,
        "throughput_tokens_per_sec": 29353.726503046368,
        "success": true,
        "error": null
      }
    ],
    "RingDilatedAttention": [
      {
        "implementation": "RingDilatedAttention",
        "seq_len": 32768,
        "batch_size": 4,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": 1,
        "mean_time_ms": 1944.6120215579867,
        "std_time_ms": 731.8987082421494,
        "peak_memory_mb": 824.1875,
        "memory_per_token": 0.006288051605224609,
        "throughput_tokens_per_sec": 67402.64821308035,
        "success": true,
        "error": null
      },
      {
        "implementation": "RingDilatedAttention",
        "seq_len": 65536,
        "batch_size": 2,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": 1,
        "mean_time_ms": 2428.7130010003843,
        "std_time_ms": 191.17803165421816,
        "peak_memory_mb": 824.25,
        "memory_per_token": 0.0062885284423828125,
        "throughput_tokens_per_sec": 53967.67750903939,
        "success": true,
        "error": null
      },
      {
        "implementation": "RingDilatedAttention",
        "seq_len": 131072,
        "batch_size": 1,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": 1,
        "mean_time_ms": 2728.9442270994186,
        "std_time_ms": 457.42492362981454,
        "peak_memory_mb": 824.375,
        "memory_per_token": 0.006289482116699219,
        "throughput_tokens_per_sec": 48030.29636824633,
        "success": true,
        "error": null
      }
    ],
    "RingMultiheadDilatedAttention": [
      {
        "implementation": "RingMultiheadDilatedAttention",
        "seq_len": 32768,
        "batch_size": 4,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 4400.007169383268,
        "std_time_ms": 212.04426456398147,
        "peak_memory_mb": 1931.1953125,
        "memory_per_token": 0.014733850955963135,
        "throughput_tokens_per_sec": 29789.04237066774,
        "success": true,
        "error": null
      },
      {
        "implementation": "RingMultiheadDilatedAttention",
        "seq_len": 65536,
        "batch_size": 2,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 4106.176765014728,
        "std_time_ms": 204.10146702662837,
        "peak_memory_mb": 1931.2578125,
        "memory_per_token": 0.014734327793121338,
        "throughput_tokens_per_sec": 31920.691071254914,
        "success": true,
        "error": null
      },
      {
        "implementation": "RingMultiheadDilatedAttention",
        "seq_len": 131072,
        "batch_size": 1,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 4713.63478495429,
        "std_time_ms": 66.12724398635854,
        "peak_memory_mb": 1931.3828125,
        "memory_per_token": 0.014735281467437744,
        "throughput_tokens_per_sec": 27806.9909909813,
        "success": true,
        "error": null
      }
    ],
    "BlockSparseRingDilatedAttention": [
      {
        "implementation": "BlockSparseRingDilatedAttention",
        "seq_len": 32768,
        "batch_size": 4,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": 1,
        "mean_time_ms": 1870.912262859444,
        "std_time_ms": 244.05750861764548,
        "peak_memory_mb": 524.65234375,
        "memory_per_token": 0.004002779722213745,
        "throughput_tokens_per_sec": 70057.80153456991,
        "success": true,
        "error": null
      },
      {
        "implementation": "BlockSparseRingDilatedAttention",
        "seq_len": 65536,
        "batch_size": 2,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": 1,
        "mean_time_ms": 2217.158436154326,
        "std_time_ms": 312.89456215666587,
        "peak_memory_mb": 522.4296875,
        "memory_per_token": 0.0039858222007751465,
        "throughput_tokens_per_sec": 59117.11037996235,
        "success": true,
        "error": null
      },
      {
        "implementation": "BlockSparseRingDilatedAttention",
        "seq_len": 131072,
        "batch_size": 1,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": 1,
        "mean_time_ms": 2861.578721242646,
        "std_time_ms": 326.25927201341506,
        "peak_memory_mb": 521.359375,
        "memory_per_token": 0.003977656364440918,
        "throughput_tokens_per_sec": 45804.08675358116,
        "success": true,
        "error": null
      }
    ]
  }
}