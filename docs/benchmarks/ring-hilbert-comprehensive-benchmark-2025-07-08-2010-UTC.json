[
  {
    "module_name": "Standard MHA",
    "batch_size": 1,
    "seq_len": 1024,
    "num_heads": 8,
    "forward_time_ms": 2.646016025543213,
    "forward_std_ms": 0.11277948432604466,
    "backward_time_ms": 22.189875030517577,
    "backward_std_ms": 0.7782321178892553,
    "total_time_ms": 24.835891056060788,
    "peak_memory_mb": 55.93017578125,
    "throughput_forward_tps": 386996.9002889083,
    "throughput_total_tps": 41230.65275526363,
    "memory_per_token_kb": 55.93017578125
  },
  {
    "module_name": "Ring+Hilbert (size=1)",
    "batch_size": 1,
    "seq_len": 1024,
    "num_heads": 8,
    "forward_time_ms": 1.658675193786621,
    "forward_std_ms": 0.31134812544969753,
    "backward_time_ms": 3.8585471630096437,
    "backward_std_ms": 0.27945720588415934,
    "total_time_ms": 5.517222356796265,
    "peak_memory_mb": 75.75439453125,
    "throughput_forward_tps": 617360.17023459,
    "throughput_total_tps": 185600.63991958,
    "memory_per_token_kb": 75.75439453125
  },
  {
    "module_name": "Standard MHA",
    "batch_size": 1,
    "seq_len": 1024,
    "num_heads": 16,
    "forward_time_ms": 3.511289596557617,
    "forward_std_ms": 0.9185619791000693,
    "backward_time_ms": 19.10516471862793,
    "backward_std_ms": 2.1074410390648177,
    "total_time_ms": 22.616454315185546,
    "peak_memory_mb": 55.96142578125,
    "throughput_forward_tps": 291630.74472806364,
    "throughput_total_tps": 45276.76998920417,
    "memory_per_token_kb": 55.96142578125
  },
  {
    "module_name": "Ring+Hilbert (size=1)",
    "batch_size": 1,
    "seq_len": 1024,
    "num_heads": 16,
    "forward_time_ms": 2.7375616073608398,
    "forward_std_ms": 0.31335914979400825,
    "backward_time_ms": 17.947436809539795,
    "backward_std_ms": 23.74255196663961,
    "total_time_ms": 20.684998416900633,
    "peak_memory_mb": 122.75439453125,
    "throughput_forward_tps": 374055.5088318879,
    "throughput_total_tps": 49504.47562825739,
    "memory_per_token_kb": 122.75439453125
  },
  {
    "module_name": "Standard MHA",
    "batch_size": 2,
    "seq_len": 1024,
    "num_heads": 8,
    "forward_time_ms": 6.960947132110595,
    "forward_std_ms": 4.0547145659174735,
    "backward_time_ms": 163.3495101928711,
    "backward_std_ms": 164.21382369920047,
    "total_time_ms": 170.31045732498168,
    "peak_memory_mb": 88.96142578125,
    "throughput_forward_tps": 294212.8364332277,
    "throughput_total_tps": 12025.098353720367,
    "memory_per_token_kb": 44.480712890625
  },
  {
    "module_name": "Ring+Hilbert (size=1)",
    "batch_size": 2,
    "seq_len": 1024,
    "num_heads": 8,
    "forward_time_ms": 7.801446437835693,
    "forward_std_ms": 5.739220490049309,
    "backward_time_ms": 30.168268489837647,
    "backward_std_ms": 29.65528764507258,
    "total_time_ms": 37.96971492767334,
    "peak_memory_mb": 146.75439453125,
    "throughput_forward_tps": 262515.42150793306,
    "throughput_total_tps": 53937.7238912943,
    "memory_per_token_kb": 73.377197265625
  },
  {
    "module_name": "Standard MHA",
    "batch_size": 2,
    "seq_len": 1024,
    "num_heads": 16,
    "forward_time_ms": 5.542092800140381,
    "forward_std_ms": 0.5890879143518405,
    "backward_time_ms": 178.9128791809082,
    "backward_std_ms": 210.92159159271748,
    "total_time_ms": 184.45497198104857,
    "peak_memory_mb": 89.02392578125,
    "throughput_forward_tps": 369535.4938748272,
    "throughput_total_tps": 11102.98073293691,
    "memory_per_token_kb": 44.511962890625
  },
  {
    "module_name": "Ring+Hilbert (size=1)",
    "batch_size": 2,
    "seq_len": 1024,
    "num_heads": 16,
    "forward_time_ms": 61.18707141876221,
    "forward_std_ms": 40.851692596503284,
    "backward_time_ms": 25.13994197845459,
    "backward_std_ms": 24.56314707595481,
    "total_time_ms": 86.3270133972168,
    "peak_memory_mb": 242.25439453125,
    "throughput_forward_tps": 33471.12310676807,
    "throughput_total_tps": 23723.744392459517,
    "memory_per_token_kb": 121.127197265625
  },
  {
    "module_name": "Standard MHA",
    "batch_size": 1,
    "seq_len": 2048,
    "num_heads": 8,
    "forward_time_ms": 40.9579460144043,
    "forward_std_ms": 58.58832969710144,
    "backward_time_ms": 495.0007919311523,
    "backward_std_ms": 483.3285061698004,
    "total_time_ms": 535.9587379455567,
    "peak_memory_mb": 76.96142578125,
    "throughput_forward_tps": 50002.507432373415,
    "throughput_total_tps": 3821.1896830909363,
    "memory_per_token_kb": 38.480712890625
  },
  {
    "module_name": "Dilated Attention",
    "batch_size": 1,
    "seq_len": 2048,
    "num_heads": 8,
    "forward_time_ms": 6.717849636077881,
    "forward_std_ms": 1.0761812767868113,
    "backward_time_ms": 324.91540603637696,
    "backward_std_ms": 461.3967439360459,
    "total_time_ms": 331.6332556724548,
    "peak_memory_mb": 99.14111328125,
    "throughput_forward_tps": 304859.4581518045,
    "throughput_total_tps": 6175.496470784444,
    "memory_per_token_kb": 49.570556640625
  },
  {
    "module_name": "Ring+Hilbert (size=1)",
    "batch_size": 1,
    "seq_len": 2048,
    "num_heads": 8,
    "forward_time_ms": 80.4716552734375,
    "forward_std_ms": 16.388949561389406,
    "backward_time_ms": 57.14064655303955,
    "backward_std_ms": 64.10945194333546,
    "total_time_ms": 137.61230182647705,
    "peak_memory_mb": 165.25830078125,
    "throughput_forward_tps": 25449.9549318456,
    "throughput_total_tps": 14882.390402730392,
    "memory_per_token_kb": 82.629150390625
  },
  {
    "module_name": "Standard MHA",
    "batch_size": 1,
    "seq_len": 2048,
    "num_heads": 16,
    "forward_time_ms": 9.371129417419434,
    "forward_std_ms": 0.48133130624805276,
    "backward_time_ms": 338.64228439331055,
    "backward_std_ms": 477.2136920691001,
    "total_time_ms": 348.01341381072996,
    "peak_memory_mb": 77.02392578125,
    "throughput_forward_tps": 218543.56169631964,
    "throughput_total_tps": 5884.83063791852,
    "memory_per_token_kb": 38.511962890625
  },
  {
    "module_name": "Dilated Attention",
    "batch_size": 1,
    "seq_len": 2048,
    "num_heads": 16,
    "forward_time_ms": 90.55948295593262,
    "forward_std_ms": 81.29801731506895,
    "backward_time_ms": 199.88092880249025,
    "backward_std_ms": 303.68098889868367,
    "total_time_ms": 290.4404117584229,
    "peak_memory_mb": 99.18798828125,
    "throughput_forward_tps": 22614.97010751025,
    "throughput_total_tps": 7051.360337911404,
    "memory_per_token_kb": 49.593994140625
  },
  {
    "module_name": "Ring+Hilbert (size=1)",
    "batch_size": 1,
    "seq_len": 2048,
    "num_heads": 16,
    "forward_time_ms": 48.20705404281616,
    "forward_std_ms": 67.56849707003668,
    "backward_time_ms": 72.66244239807129,
    "backward_std_ms": 105.82265191550476,
    "total_time_ms": 120.86949644088745,
    "peak_memory_mb": 293.25830078125,
    "throughput_forward_tps": 42483.409133049776,
    "throughput_total_tps": 16943.89453340361,
    "memory_per_token_kb": 146.629150390625
  },
  {
    "module_name": "Standard MHA",
    "batch_size": 2,
    "seq_len": 2048,
    "num_heads": 8,
    "forward_time_ms": 219.74568367004395,
    "forward_std_ms": 193.7518833192749,
    "backward_time_ms": 530.2884490966796,
    "backward_std_ms": 438.9427976395683,
    "total_time_ms": 750.0341327667236,
    "peak_memory_mb": 143.02392578125,
    "throughput_forward_tps": 18639.729033996824,
    "throughput_total_tps": 5461.084797422069,
    "memory_per_token_kb": 35.7559814453125
  },
  {
    "module_name": "Dilated Attention",
    "batch_size": 2,
    "seq_len": 2048,
    "num_heads": 8,
    "forward_time_ms": 29.603423881530762,
    "forward_std_ms": 34.91318468790504,
    "backward_time_ms": 260.5103424072266,
    "backward_std_ms": 369.9613403850246,
    "total_time_ms": 290.11376628875735,
    "peak_memory_mb": 155.73486328125,
    "throughput_forward_tps": 138362.37377107746,
    "throughput_total_tps": 14118.599239179677,
    "memory_per_token_kb": 38.9337158203125
  },
  {
    "module_name": "Ring+Hilbert (size=1)",
    "batch_size": 2,
    "seq_len": 2048,
    "num_heads": 8,
    "forward_time_ms": 152.97599029541016,
    "forward_std_ms": 19.764789556493753,
    "backward_time_ms": 93.31997871398926,
    "backward_std_ms": 119.93971632316996,
    "total_time_ms": 246.2959690093994,
    "peak_memory_mb": 338.25830078125,
    "throughput_forward_tps": 26775.443597980717,
    "throughput_total_tps": 16630.398038888263,
    "memory_per_token_kb": 84.5645751953125
  },
  {
    "module_name": "Standard MHA",
    "batch_size": 2,
    "seq_len": 2048,
    "num_heads": 16,
    "forward_time_ms": 241.82968711853027,
    "forward_std_ms": 224.02255405974822,
    "backward_time_ms": 513.1176254272461,
    "backward_std_ms": 467.2057423307841,
    "total_time_ms": 754.9473125457764,
    "peak_memory_mb": 143.14892578125,
    "throughput_forward_tps": 16937.540005137536,
    "throughput_total_tps": 5425.54418292818,
    "memory_per_token_kb": 35.7872314453125
  },
  {
    "module_name": "Dilated Attention",
    "batch_size": 2,
    "seq_len": 2048,
    "num_heads": 16,
    "forward_time_ms": 241.7012680053711,
    "forward_std_ms": 91.57812575578578,
    "backward_time_ms": 128.93491744995117,
    "backward_std_ms": 113.55389273459198,
    "total_time_ms": 370.6361854553223,
    "peak_memory_mb": 155.82861328125,
    "throughput_forward_tps": 16946.539146451552,
    "throughput_total_tps": 11051.268496539567,
    "memory_per_token_kb": 38.9571533203125
  },
  {
    "module_name": "Ring+Hilbert (size=1)",
    "batch_size": 2,
    "seq_len": 2048,
    "num_heads": 16,
    "forward_time_ms": 129.9406768798828,
    "forward_std_ms": 87.71910777111187,
    "backward_time_ms": 248.80517501831054,
    "backward_std_ms": 213.46129603289924,
    "total_time_ms": 378.74585189819334,
    "peak_memory_mb": 594.25830078125,
    "throughput_forward_tps": 31522.076830385788,
    "throughput_total_tps": 10814.639894989537,
    "memory_per_token_kb": 148.5645751953125
  },
  {
    "module_name": "Standard MHA",
    "batch_size": 1,
    "seq_len": 4096,
    "num_heads": 8,
    "forward_time_ms": 276.1930633544922,
    "forward_std_ms": 294.4665886832368,
    "backward_time_ms": 1203.4486328125,
    "backward_std_ms": 853.0614621762107,
    "total_time_ms": 1479.641696166992,
    "peak_memory_mb": 119.02392578125,
    "throughput_forward_tps": 14830.20590833162,
    "throughput_total_tps": 2768.237750132804,
    "memory_per_token_kb": 29.7559814453125
  },
  {
    "module_name": "Dilated Attention",
    "batch_size": 1,
    "seq_len": 4096,
    "num_heads": 8,
    "forward_time_ms": 22.187615966796876,
    "forward_std_ms": 19.591208219533144,
    "backward_time_ms": 316.3162788391113,
    "backward_std_ms": 260.91613525027947,
    "total_time_ms": 338.5038948059082,
    "peak_memory_mb": 155.73486328125,
    "throughput_forward_tps": 184607.4858213494,
    "throughput_total_tps": 12100.30390447522,
    "memory_per_token_kb": 38.9337158203125
  },
  {
    "module_name": "Ring+Hilbert (size=1)",
    "batch_size": 1,
    "seq_len": 4096,
    "num_heads": 8,
    "forward_time_ms": 62.42181262969971,
    "forward_std_ms": 32.37213661119409,
    "backward_time_ms": 111.61007385253906,
    "backward_std_ms": 104.38656691161637,
    "total_time_ms": 174.03188648223878,
    "peak_memory_mb": 351.32861328125,
    "throughput_forward_tps": 65618.08809203278,
    "throughput_total_tps": 23535.91679544327,
    "memory_per_token_kb": 87.8321533203125
  },
  {
    "module_name": "Standard MHA",
    "batch_size": 1,
    "seq_len": 4096,
    "num_heads": 16,
    "forward_time_ms": 275.2753662109375,
    "forward_std_ms": 301.0026963474354,
    "backward_time_ms": 1481.346875,
    "backward_std_ms": 756.2667712223458,
    "total_time_ms": 1756.6222412109373,
    "peak_memory_mb": 119.14892578125,
    "throughput_forward_tps": 14879.645993682287,
    "throughput_total_tps": 2331.747773600088,
    "memory_per_token_kb": 29.7872314453125
  },
  {
    "module_name": "Dilated Attention",
    "batch_size": 1,
    "seq_len": 4096,
    "num_heads": 16,
    "forward_time_ms": 204.48952560424806,
    "forward_std_ms": 114.9314631818725,
    "backward_time_ms": 140.14588165283203,
    "backward_std_ms": 152.6434635708179,
    "total_time_ms": 344.6354072570801,
    "peak_memory_mb": 155.82861328125,
    "throughput_forward_tps": 20030.365799405572,
    "throughput_total_tps": 11885.023749009622,
    "memory_per_token_kb": 38.9571533203125
  },
  {
    "module_name": "Ring+Hilbert (size=1)",
    "batch_size": 1,
    "seq_len": 4096,
    "num_heads": 16,
    "forward_time_ms": 243.16231689453124,
    "forward_std_ms": 33.91224703491489,
    "backward_time_ms": 309.85689010620115,
    "backward_std_ms": 210.59468101605313,
    "total_time_ms": 553.0192070007324,
    "peak_memory_mb": 606.82861328125,
    "throughput_forward_tps": 16844.715300918073,
    "throughput_total_tps": 7406.614360131212,
    "memory_per_token_kb": 151.7071533203125
  },
  {
    "module_name": "Standard MHA",
    "batch_size": 2,
    "seq_len": 4096,
    "num_heads": 8,
    "forward_time_ms": 628.6012725830078,
    "forward_std_ms": 481.6786372427488,
    "backward_time_ms": 2853.5902099609375,
    "backward_std_ms": 660.6239990757493,
    "total_time_ms": 3482.1914825439453,
    "peak_memory_mb": 251.14892578125,
    "throughput_forward_tps": 13032.108519822052,
    "throughput_total_tps": 2352.541507572485,
    "memory_per_token_kb": 31.39361572265625
  },
  {
    "module_name": "Dilated Attention",
    "batch_size": 2,
    "seq_len": 4096,
    "num_heads": 8,
    "forward_time_ms": 357.9903991699219,
    "forward_std_ms": 151.29702799394184,
    "backward_time_ms": 697.5338592529297,
    "backward_std_ms": 688.733728908811,
    "total_time_ms": 1055.5242584228515,
    "peak_memory_mb": 275.92236328125,
    "throughput_forward_tps": 22883.295247567876,
    "throughput_total_tps": 7761.072220396302,
    "memory_per_token_kb": 34.49029541015625
  },
  {
    "module_name": "Ring+Hilbert (size=1)",
    "batch_size": 2,
    "seq_len": 4096,
    "num_heads": 8,
    "forward_time_ms": 84.59550132751465,
    "forward_std_ms": 82.71666850513799,
    "backward_time_ms": 493.44636154174805,
    "backward_std_ms": 350.5750316625207,
    "total_time_ms": 578.0418628692627,
    "peak_memory_mb": 660.32861328125,
    "throughput_forward_tps": 96837.30070094821,
    "throughput_total_tps": 14171.983944790532,
    "memory_per_token_kb": 82.54107666015625
  },
  {
    "module_name": "Standard MHA",
    "batch_size": 2,
    "seq_len": 4096,
    "num_heads": 16,
    "forward_time_ms": 968.3542175292969,
    "forward_std_ms": 529.6396230260989,
    "backward_time_ms": 2584.6556396484375,
    "backward_std_ms": 836.7263364698905,
    "total_time_ms": 3553.0098571777344,
    "peak_memory_mb": 251.39892578125,
    "throughput_forward_tps": 8459.714277799547,
    "throughput_total_tps": 2305.6507944808122,
    "memory_per_token_kb": 31.42486572265625
  },
  {
    "module_name": "Dilated Attention",
    "batch_size": 2,
    "seq_len": 4096,
    "num_heads": 16,
    "forward_time_ms": 518.1587524414062,
    "forward_std_ms": 59.48603052329489,
    "backward_time_ms": 1001.1021148681641,
    "backward_std_ms": 640.5355173952803,
    "total_time_ms": 1519.2608673095704,
    "peak_memory_mb": 276.10986328125,
    "throughput_forward_tps": 15809.826547176497,
    "throughput_total_tps": 5392.095706714972,
    "memory_per_token_kb": 34.51373291015625
  },
  {
    "module_name": "Ring+Hilbert (size=1)",
    "batch_size": 2,
    "seq_len": 4096,
    "num_heads": 16,
    "forward_time_ms": 428.0598571777344,
    "forward_std_ms": 45.35229160873402,
    "backward_time_ms": 616.8066162109375,
    "backward_std_ms": 479.9658037127371,
    "total_time_ms": 1044.866473388672,
    "peak_memory_mb": 1173.32861328125,
    "throughput_forward_tps": 19137.51047344439,
    "throughput_total_tps": 7840.2362489744855,
    "memory_per_token_kb": 146.66607666015625
  }
]