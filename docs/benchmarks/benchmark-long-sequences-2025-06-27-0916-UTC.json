{
  "metadata": {
    "timestamp": "2025-06-27-0916-UTC",
    "device": "NVIDIA GeForce GTX 1080",
    "total_memory_gb": 7.8841552734375,
    "dtype": "float16",
    "num_heads": 8,
    "head_dim": 64
  },
  "results": {
    "ImprovedDilatedAttention": [
      {
        "implementation": "ImprovedDilatedAttention",
        "seq_len": 32768,
        "batch_size": 4,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 1171.7221573926508,
        "std_time_ms": 22.378783207386732,
        "peak_memory_mb": 688.0625,
        "memory_per_token": 0.005249500274658203,
        "throughput_tokens_per_sec": 111862.69643621412,
        "success": true,
        "error": null
      },
      {
        "implementation": "ImprovedDilatedAttention",
        "seq_len": 65536,
        "batch_size": 2,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 1185.5315607972443,
        "std_time_ms": 40.20388098433614,
        "peak_memory_mb": 696.25,
        "memory_per_token": 0.0053119659423828125,
        "throughput_tokens_per_sec": 110559.68844208324,
        "success": true,
        "error": null
      },
      {
        "implementation": "ImprovedDilatedAttention",
        "seq_len": 131072,
        "batch_size": 1,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 1381.3786986283958,
        "std_time_ms": 33.74571865424514,
        "peak_memory_mb": 696.375,
        "memory_per_token": 0.005312919616699219,
        "throughput_tokens_per_sec": 94884.91470886626,
        "success": true,
        "error": null
      }
    ],
    "ImprovedMultiheadDilatedAttention": [
      {
        "implementation": "ImprovedMultiheadDilatedAttention",
        "seq_len": 32768,
        "batch_size": 4,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 2667.837902903557,
        "std_time_ms": 39.66079466044903,
        "peak_memory_mb": 1850.1953125,
        "memory_per_token": 0.014115869998931885,
        "throughput_tokens_per_sec": 49130.42125136127,
        "success": true,
        "error": null
      },
      {
        "implementation": "ImprovedMultiheadDilatedAttention",
        "seq_len": 65536,
        "batch_size": 2,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 2808.9510682038963,
        "std_time_ms": 323.7330918200314,
        "peak_memory_mb": 1850.2578125,
        "memory_per_token": 0.014116346836090088,
        "throughput_tokens_per_sec": 46662.25819441214,
        "success": true,
        "error": null
      },
      {
        "implementation": "ImprovedMultiheadDilatedAttention",
        "seq_len": 131072,
        "batch_size": 1,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 3262.29265704751,
        "std_time_ms": 334.05160810798407,
        "peak_memory_mb": 1850.3828125,
        "memory_per_token": 0.014117300510406494,
        "throughput_tokens_per_sec": 40177.87911113553,
        "success": true,
        "error": null
      }
    ],
    "RingDilatedAttention": [
      {
        "implementation": "RingDilatedAttention",
        "seq_len": 32768,
        "batch_size": 4,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": 1,
        "mean_time_ms": 1200.2497036010027,
        "std_time_ms": 16.832252964377403,
        "peak_memory_mb": 824.1875,
        "memory_per_token": 0.006288051605224609,
        "throughput_tokens_per_sec": 109203.94281852877,
        "success": true,
        "error": null
      },
      {
        "implementation": "RingDilatedAttention",
        "seq_len": 65536,
        "batch_size": 2,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": 1,
        "mean_time_ms": 1239.6517526358366,
        "std_time_ms": 22.767823189496994,
        "peak_memory_mb": 824.25,
        "memory_per_token": 0.0062885284423828125,
        "throughput_tokens_per_sec": 105732.92033129893,
        "success": true,
        "error": null
      },
      {
        "implementation": "RingDilatedAttention",
        "seq_len": 131072,
        "batch_size": 1,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": 1,
        "mean_time_ms": 1220.1568032614887,
        "std_time_ms": 12.58124178275466,
        "peak_memory_mb": 824.375,
        "memory_per_token": 0.006289482116699219,
        "throughput_tokens_per_sec": 107422.2588847954,
        "success": true,
        "error": null
      }
    ],
    "RingMultiheadDilatedAttention": [
      {
        "implementation": "RingMultiheadDilatedAttention",
        "seq_len": 32768,
        "batch_size": 4,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 2447.666520252824,
        "std_time_ms": 16.89528487622738,
        "peak_memory_mb": 1931.1953125,
        "memory_per_token": 0.014733850955963135,
        "throughput_tokens_per_sec": 53549.7784994262,
        "success": true,
        "error": null
      },
      {
        "implementation": "RingMultiheadDilatedAttention",
        "seq_len": 65536,
        "batch_size": 2,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 3036.95571096614,
        "std_time_ms": 339.52482929453254,
        "peak_memory_mb": 1931.2578125,
        "memory_per_token": 0.014734327793121338,
        "throughput_tokens_per_sec": 43159.00937465511,
        "success": true,
        "error": null
      },
      {
        "implementation": "RingMultiheadDilatedAttention",
        "seq_len": 131072,
        "batch_size": 1,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 3142.6027747802436,
        "std_time_ms": 384.8247998394072,
        "peak_memory_mb": 1931.3828125,
        "memory_per_token": 0.014735281467437744,
        "throughput_tokens_per_sec": 41708.1029304334,
        "success": true,
        "error": null
      }
    ],
    "BlockSparseRingDilatedAttention": [
      {
        "implementation": "BlockSparseRingDilatedAttention",
        "seq_len": 32768,
        "batch_size": 4,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": 1,
        "mean_time_ms": 948.7877795472741,
        "std_time_ms": 314.4663106650114,
        "peak_memory_mb": 524.65234375,
        "memory_per_token": 0.004002779722213745,
        "throughput_tokens_per_sec": 138146.80461266337,
        "success": true,
        "error": null
      },
      {
        "implementation": "BlockSparseRingDilatedAttention",
        "seq_len": 65536,
        "batch_size": 2,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": 1,
        "mean_time_ms": 1416.4262092672288,
        "std_time_ms": 265.76329255476594,
        "peak_memory_mb": 522.4296875,
        "memory_per_token": 0.0039858222007751465,
        "throughput_tokens_per_sec": 92537.1185187321,
        "success": true,
        "error": null
      },
      {
        "implementation": "BlockSparseRingDilatedAttention",
        "seq_len": 131072,
        "batch_size": 1,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": 1,
        "mean_time_ms": 1499.747656751424,
        "std_time_ms": 32.708723563700914,
        "peak_memory_mb": 521.359375,
        "memory_per_token": 0.003977656364440918,
        "throughput_tokens_per_sec": 87396.03586640213,
        "success": true,
        "error": null
      }
    ]
  }
}