# Ring Attention with Dilated Patterns Benchmark\nGenerated: 2025-06-27T21:30:48.715472Z\n\n## Configuration\n- Device: cuda\n- Data type: torch.float16\n- Batch size: 1\n- Heads: 8\n- Head dim: 64\n- Sequence lengths: [1024, 2048]\n\n## Results\n\n### ImprovedDilatedAttention\n- Sequence length: 1,024\n- Time: 6.8ms\n- Memory: 19.9MB\n- Throughput: 150164 tokens/sec\n- Correctness: 0.000\n- Segment lengths: [256, 512]\n- Dilation rates: [1, 2]\n\n### RingDilatedV2_single\n- Sequence length: 1,024\n- Time: 0.7ms\n- Memory: 27.6MB\n- Throughput: 1415858 tokens/sec\n- Correctness: 1.000\n- Ring size: 1\n- Segment lengths: [256, 512]\n- Dilation rates: [1, 2]\n\n### RingDilatedV2_ring2\n- Sequence length: 1,024\n- Time: 1.1ms\n- Memory: 23.1MB\n- Throughput: 934605 tokens/sec\n- Correctness: 1.000\n- Ring size: 2\n- Segment lengths: [256, 512]\n- Dilation rates: [1, 2]\n\n### ImprovedDilatedAttention\n- Sequence length: 2,048\n- Time: 12.1ms\n- Memory: 31.6MB\n- Throughput: 169371 tokens/sec\n- Correctness: 0.000\n- Segment lengths: [512, 1024]\n- Dilation rates: [1, 2]\n\n### RingDilatedV2_single\n- Sequence length: 2,048\n- Time: 2.1ms\n- Memory: 63.1MB\n- Throughput: 975982 tokens/sec\n- Correctness: 1.000\n- Ring size: 1\n- Segment lengths: [512, 1024]\n- Dilation rates: [1, 2]\n\n### RingDilatedV2_ring2\n- Sequence length: 2,048\n- Time: 2.2ms\n- Memory: 46.2MB\n- Throughput: 949738 tokens/sec\n- Correctness: 1.000\n- Ring size: 2\n- Segment lengths: [512, 1024]\n- Dilation rates: [1, 2]\n\n