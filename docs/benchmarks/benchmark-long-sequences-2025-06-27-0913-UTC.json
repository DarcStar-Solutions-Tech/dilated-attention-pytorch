{
  "metadata": {
    "timestamp": "2025-06-27-0913-UTC",
    "device": "NVIDIA GeForce GTX 1080",
    "total_memory_gb": 7.8841552734375,
    "dtype": "float16",
    "num_heads": 8,
    "head_dim": 64
  },
  "results": {
    "ImprovedDilatedAttention": [
      {
        "implementation": "ImprovedDilatedAttention",
        "seq_len": 16384,
        "batch_size": 8,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 884.2166280373931,
        "std_time_ms": 25.80689032359238,
        "peak_memory_mb": 776.03125,
        "memory_per_token": 0.0059206485748291016,
        "throughput_tokens_per_sec": 148235.16754138333,
        "success": true,
        "error": null
      },
      {
        "implementation": "ImprovedDilatedAttention",
        "seq_len": 32768,
        "batch_size": 4,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 1280.485817231238,
        "std_time_ms": 208.20961575977677,
        "peak_memory_mb": 696.1875,
        "memory_per_token": 0.005311489105224609,
        "throughput_tokens_per_sec": 102361.14936705327,
        "success": true,
        "error": null
      }
    ],
    "ImprovedMultiheadDilatedAttention": [
      {
        "implementation": "ImprovedMultiheadDilatedAttention",
        "seq_len": 16384,
        "batch_size": 8,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 1609.3329734479387,
        "std_time_ms": 234.65897816066206,
        "peak_memory_mb": 1938.1640625,
        "memory_per_token": 0.014787018299102783,
        "throughput_tokens_per_sec": 81444.92293548357,
        "success": true,
        "error": null
      },
      {
        "implementation": "ImprovedMultiheadDilatedAttention",
        "seq_len": 32768,
        "batch_size": 4,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 2372.4755592023334,
        "std_time_ms": 208.2186090487171,
        "peak_memory_mb": 1850.1953125,
        "memory_per_token": 0.014115869998931885,
        "throughput_tokens_per_sec": 55246.93373198274,
        "success": true,
        "error": null
      }
    ],
    "RingDilatedAttention": [
      {
        "implementation": "RingDilatedAttention",
        "seq_len": 16384,
        "batch_size": 8,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": 2,
        "mean_time_ms": 1394.3796964983146,
        "std_time_ms": 522.1117066630791,
        "peak_memory_mb": 976.15625,
        "memory_per_token": 0.007447481155395508,
        "throughput_tokens_per_sec": 94000.2212662442,
        "success": true,
        "error": null
      },
      {
        "implementation": "RingDilatedAttention",
        "seq_len": 32768,
        "batch_size": 4,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": 1,
        "mean_time_ms": 1163.6321091403563,
        "std_time_ms": 21.047343155588774,
        "peak_memory_mb": 824.1875,
        "memory_per_token": 0.006288051605224609,
        "throughput_tokens_per_sec": 112640.41183671927,
        "success": true,
        "error": null
      }
    ],
    "RingMultiheadDilatedAttention": [
      {
        "implementation": "RingMultiheadDilatedAttention",
        "seq_len": 16384,
        "batch_size": 8,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 1926.4780419568222,
        "std_time_ms": 236.54143482470968,
        "peak_memory_mb": 1931.1640625,
        "memory_per_token": 0.014733612537384033,
        "throughput_tokens_per_sec": 68037.11080291549,
        "success": true,
        "error": null
      },
      {
        "implementation": "RingMultiheadDilatedAttention",
        "seq_len": 32768,
        "batch_size": 4,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": null,
        "mean_time_ms": 2364.99607997636,
        "std_time_ms": 100.68727409576123,
        "peak_memory_mb": 1931.1953125,
        "memory_per_token": 0.014733850955963135,
        "throughput_tokens_per_sec": 55421.656344271905,
        "success": true,
        "error": null
      }
    ],
    "BlockSparseRingDilatedAttention": [
      {
        "implementation": "BlockSparseRingDilatedAttention",
        "seq_len": 16384,
        "batch_size": 8,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": 1,
        "mean_time_ms": 887.8422891721129,
        "std_time_ms": 314.1714262900195,
        "peak_memory_mb": 529.638671875,
        "memory_per_token": 0.004040822386741638,
        "throughput_tokens_per_sec": 147629.82299730374,
        "success": true,
        "error": null
      },
      {
        "implementation": "BlockSparseRingDilatedAttention",
        "seq_len": 32768,
        "batch_size": 4,
        "num_heads": 8,
        "head_dim": 64,
        "ring_size": 1,
        "mean_time_ms": 703.4796777491769,
        "std_time_ms": 47.56977490240244,
        "peak_memory_mb": 524.65234375,
        "memory_per_token": 0.004002779722213745,
        "throughput_tokens_per_sec": 186319.52584525585,
        "success": true,
        "error": null
      }
    ]
  }
}