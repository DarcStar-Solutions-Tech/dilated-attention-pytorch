{
  "config": {
    "device": "cuda",
    "dtype": "torch.float32",
    "benchmark_config": {
      "batch_sizes": [
        1,
        2,
        4
      ],
      "seq_lengths": [
        1024,
        2048,
        4096
      ],
      "num_heads_list": [
        8,
        16
      ],
      "head_dim": 64,
      "segment_lengths": [
        [
          512,
          1024
        ],
        [
          1024,
          2048
        ],
        [
          2048,
          4096
        ]
      ],
      "dilation_rates": [
        [
          1,
          2
        ],
        [
          1,
          2
        ],
        [
          1,
          2
        ]
      ],
      "warmup_steps": 3,
      "benchmark_steps": 10,
      "device": "cuda",
      "use_fp16": true,
      "use_memory_pool": true,
      "memory_pool_size": null,
      "use_pattern_cache": true,
      "pattern_cache_size": 100,
      "save_plots": true,
      "save_csv": true,
      "verbose": true
    }
  },
  "results": [
    {
      "implementation": "standard",
      "batch_size": 1,
      "seq_length": 1024,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 1.1609647423028946,
      "memory_mb": 29.03125,
      "throughput": 882025.063025419,
      "success": true,
      "error": null
    },
    {
      "implementation": "standard",
      "batch_size": 1,
      "seq_length": 1024,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 1.8438897095620632,
      "memory_mb": 49.03125,
      "throughput": 555347.7492117503,
      "success": true,
      "error": null
    },
    {
      "implementation": "standard",
      "batch_size": 1,
      "seq_length": 2048,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 3.295239992439747,
      "memory_mb": 49.03125,
      "throughput": 621502.5323493028,
      "success": true,
      "error": null
    },
    {
      "implementation": "standard",
      "batch_size": 1,
      "seq_length": 2048,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 5.788880120962858,
      "memory_mb": 89.03125,
      "throughput": 353781.7258615745,
      "success": true,
      "error": null
    },
    {
      "implementation": "standard",
      "batch_size": 1,
      "seq_length": 4096,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 10.461020935326815,
      "memory_mb": 89.03125,
      "throughput": 391548.781454765,
      "success": true,
      "error": null
    },
    {
      "implementation": "standard",
      "batch_size": 1,
      "seq_length": 4096,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 42.82171353697777,
      "memory_mb": 169.03125,
      "throughput": 95652.40766143063,
      "success": true,
      "error": null
    },
    {
      "implementation": "standard",
      "batch_size": 2,
      "seq_length": 1024,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 4.761954676359892,
      "memory_mb": 48.03125,
      "throughput": 430075.49193339265,
      "success": true,
      "error": null
    },
    {
      "implementation": "standard",
      "batch_size": 2,
      "seq_length": 1024,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 13.34391413256526,
      "memory_mb": 89.03125,
      "throughput": 153478.20584381177,
      "success": true,
      "error": null
    },
    {
      "implementation": "standard",
      "batch_size": 2,
      "seq_length": 2048,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 36.914205737411976,
      "memory_mb": 89.03125,
      "throughput": 110959.99272303907,
      "success": true,
      "error": null
    },
    {
      "implementation": "standard",
      "batch_size": 2,
      "seq_length": 2048,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 11.618483159691095,
      "memory_mb": 169.03125,
      "throughput": 352541.71682329156,
      "success": true,
      "error": null
    },
    {
      "implementation": "standard",
      "batch_size": 2,
      "seq_length": 4096,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 121.90206795930862,
      "memory_mb": 169.03125,
      "throughput": 67201.48507024934,
      "success": true,
      "error": null
    },
    {
      "implementation": "standard",
      "batch_size": 2,
      "seq_length": 4096,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 197.11764827370644,
      "memory_mb": 328.03125,
      "throughput": 41558.93737442043,
      "success": true,
      "error": null
    },
    {
      "implementation": "standard",
      "batch_size": 4,
      "seq_length": 1024,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 6.019826885312796,
      "memory_mb": 89.03125,
      "throughput": 680418.237606374,
      "success": true,
      "error": null
    },
    {
      "implementation": "standard",
      "batch_size": 4,
      "seq_length": 1024,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 21.665091905742884,
      "memory_mb": 169.03125,
      "throughput": 189059.89496006945,
      "success": true,
      "error": null
    },
    {
      "implementation": "standard",
      "batch_size": 4,
      "seq_length": 2048,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 74.53636452555656,
      "memory_mb": 169.03125,
      "throughput": 109906.08479692054,
      "success": true,
      "error": null
    },
    {
      "implementation": "standard",
      "batch_size": 4,
      "seq_length": 2048,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 147.86205776035786,
      "memory_mb": 328.03125,
      "throughput": 55402.98927312976,
      "success": true,
      "error": null
    },
    {
      "implementation": "standard",
      "batch_size": 4,
      "seq_length": 4096,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 200.98067400977015,
      "memory_mb": 328.03125,
      "throughput": 81520.2759206765,
      "success": true,
      "error": null
    },
    {
      "implementation": "standard",
      "batch_size": 4,
      "seq_length": 4096,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 425.7173393853009,
      "memory_mb": 648.03125,
      "throughput": 38485.62998081564,
      "success": true,
      "error": null
    },
    {
      "implementation": "improved",
      "batch_size": 1,
      "seq_length": 1024,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 0.7119788788259029,
      "memory_mb": 25.03125,
      "throughput": 1438244.9121084027,
      "success": true,
      "error": null
    },
    {
      "implementation": "improved",
      "batch_size": 1,
      "seq_length": 1024,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 0.7051308639347553,
      "memory_mb": 41.03125,
      "throughput": 1452212.7060016892,
      "success": true,
      "error": null
    },
    {
      "implementation": "improved",
      "batch_size": 1,
      "seq_length": 2048,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 1.0728598572313786,
      "memory_mb": 41.03125,
      "throughput": 1908916.6084422874,
      "success": true,
      "error": null
    },
    {
      "implementation": "improved",
      "batch_size": 1,
      "seq_length": 2048,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 1.2246123515069485,
      "memory_mb": 73.03125,
      "throughput": 1672365.9511353374,
      "success": true,
      "error": null
    },
    {
      "implementation": "improved",
      "batch_size": 1,
      "seq_length": 4096,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 15.289020352065563,
      "memory_mb": 73.03125,
      "throughput": 267904.6731366687,
      "success": true,
      "error": null
    },
    {
      "implementation": "improved",
      "batch_size": 1,
      "seq_length": 4096,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 31.619525607675314,
      "memory_mb": 137.03125,
      "throughput": 129540.21040106111,
      "success": true,
      "error": null
    },
    {
      "implementation": "improved",
      "batch_size": 2,
      "seq_length": 1024,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 6.1293937265872955,
      "memory_mb": 40.03125,
      "throughput": 334127.6627599316,
      "success": true,
      "error": null
    },
    {
      "implementation": "improved",
      "batch_size": 2,
      "seq_length": 1024,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 6.52187280356884,
      "memory_mb": 73.03125,
      "throughput": 314020.2303361869,
      "success": true,
      "error": null
    },
    {
      "implementation": "improved",
      "batch_size": 2,
      "seq_length": 2048,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 2.5166801176965237,
      "memory_mb": 73.03125,
      "throughput": 1627540.9700256232,
      "success": true,
      "error": null
    },
    {
      "implementation": "improved",
      "batch_size": 2,
      "seq_length": 2048,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 2.02619107440114,
      "memory_mb": 137.03125,
      "throughput": 2021527.017737264,
      "success": true,
      "error": null
    },
    {
      "implementation": "improved",
      "batch_size": 2,
      "seq_length": 4096,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 3.6398885771632195,
      "memory_mb": 137.03125,
      "throughput": 2250618.34348361,
      "success": true,
      "error": null
    },
    {
      "implementation": "improved",
      "batch_size": 2,
      "seq_length": 4096,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 3.906549885869026,
      "memory_mb": 264.03125,
      "throughput": 2096991.0123591472,
      "success": true,
      "error": null
    },
    {
      "implementation": "improved",
      "batch_size": 4,
      "seq_length": 1024,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 1.8213988281786442,
      "memory_mb": 73.03125,
      "throughput": 2248821.0361351245,
      "success": true,
      "error": null
    },
    {
      "implementation": "improved",
      "batch_size": 4,
      "seq_length": 1024,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 1.8312889151275158,
      "memory_mb": 137.03125,
      "throughput": 2236676.018821852,
      "success": true,
      "error": null
    },
    {
      "implementation": "improved",
      "batch_size": 4,
      "seq_length": 2048,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 3.1444255262613297,
      "memory_mb": 137.03125,
      "throughput": 2605245.356133511,
      "success": true,
      "error": null
    },
    {
      "implementation": "improved",
      "batch_size": 4,
      "seq_length": 2048,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 3.7792702205479145,
      "memory_mb": 264.03125,
      "throughput": 2167614.254058905,
      "success": true,
      "error": null
    },
    {
      "implementation": "improved",
      "batch_size": 4,
      "seq_length": 4096,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 14.75157355889678,
      "memory_mb": 264.03125,
      "throughput": 1110661.173507059,
      "success": true,
      "error": null
    },
    {
      "implementation": "improved",
      "batch_size": 4,
      "seq_length": 4096,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 9.814221411943436,
      "memory_mb": 520.03125,
      "throughput": 1669414.1401845142,
      "success": true,
      "error": null
    },
    {
      "implementation": "multihead_standard",
      "batch_size": 1,
      "seq_length": 1024,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 1.9730750471353533,
      "memory_mb": 43.15625,
      "throughput": 518986.84821274993,
      "success": true,
      "error": null
    },
    {
      "implementation": "multihead_standard",
      "batch_size": 1,
      "seq_length": 1024,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 0.0,
      "memory_mb": 0.0,
      "throughput": 0.0,
      "success": false,
      "error": "Input embedding dimension (1024) doesn't match expected (512)"
    },
    {
      "implementation": "multihead_standard",
      "batch_size": 1,
      "seq_length": 2048,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 6.201490294188261,
      "memory_mb": 69.15625,
      "throughput": 330243.200077131,
      "success": true,
      "error": null
    },
    {
      "implementation": "multihead_standard",
      "batch_size": 1,
      "seq_length": 2048,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 0.0,
      "memory_mb": 0.0,
      "throughput": 0.0,
      "success": false,
      "error": "Input embedding dimension (1024) doesn't match expected (512)"
    },
    {
      "implementation": "multihead_standard",
      "batch_size": 1,
      "seq_length": 4096,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 13.810793962329626,
      "memory_mb": 121.15625,
      "throughput": 296579.6181720084,
      "success": true,
      "error": null
    },
    {
      "implementation": "multihead_standard",
      "batch_size": 1,
      "seq_length": 4096,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 0.0,
      "memory_mb": 0.0,
      "throughput": 0.0,
      "success": false,
      "error": "Input embedding dimension (1024) doesn't match expected (512)"
    },
    {
      "implementation": "multihead_standard",
      "batch_size": 2,
      "seq_length": 1024,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 7.470151130110025,
      "memory_mb": 69.15625,
      "throughput": 274157.7732939167,
      "success": true,
      "error": null
    },
    {
      "implementation": "multihead_standard",
      "batch_size": 2,
      "seq_length": 1024,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 0.0,
      "memory_mb": 0.0,
      "throughput": 0.0,
      "success": false,
      "error": "Input embedding dimension (1024) doesn't match expected (512)"
    },
    {
      "implementation": "multihead_standard",
      "batch_size": 2,
      "seq_length": 2048,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 26.031699404120445,
      "memory_mb": 121.15625,
      "throughput": 157346.62330003938,
      "success": true,
      "error": null
    },
    {
      "implementation": "multihead_standard",
      "batch_size": 2,
      "seq_length": 2048,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 0.0,
      "memory_mb": 0.0,
      "throughput": 0.0,
      "success": false,
      "error": "Input embedding dimension (1024) doesn't match expected (512)"
    },
    {
      "implementation": "multihead_standard",
      "batch_size": 2,
      "seq_length": 4096,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 122.79179347679019,
      "memory_mb": 225.15625,
      "throughput": 66714.55614457194,
      "success": true,
      "error": null
    },
    {
      "implementation": "multihead_standard",
      "batch_size": 2,
      "seq_length": 4096,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 0.0,
      "memory_mb": 0.0,
      "throughput": 0.0,
      "success": false,
      "error": "Input embedding dimension (1024) doesn't match expected (512)"
    },
    {
      "implementation": "multihead_standard",
      "batch_size": 4,
      "seq_length": 1024,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 11.069702543318272,
      "memory_mb": 121.15625,
      "throughput": 370018.9760268099,
      "success": true,
      "error": null
    },
    {
      "implementation": "multihead_standard",
      "batch_size": 4,
      "seq_length": 1024,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 0.0,
      "memory_mb": 0.0,
      "throughput": 0.0,
      "success": false,
      "error": "Input embedding dimension (1024) doesn't match expected (512)"
    },
    {
      "implementation": "multihead_standard",
      "batch_size": 4,
      "seq_length": 2048,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 48.73163681477308,
      "memory_mb": 225.15625,
      "throughput": 168104.3473080424,
      "success": true,
      "error": null
    },
    {
      "implementation": "multihead_standard",
      "batch_size": 4,
      "seq_length": 2048,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 0.0,
      "memory_mb": 0.0,
      "throughput": 0.0,
      "success": false,
      "error": "Input embedding dimension (1024) doesn't match expected (512)"
    },
    {
      "implementation": "multihead_standard",
      "batch_size": 4,
      "seq_length": 4096,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 83.13756519928575,
      "memory_mb": 432.15625,
      "throughput": 197070.9625754202,
      "success": true,
      "error": null
    },
    {
      "implementation": "multihead_standard",
      "batch_size": 4,
      "seq_length": 4096,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 0.0,
      "memory_mb": 0.0,
      "throughput": 0.0,
      "success": false,
      "error": "Input embedding dimension (1024) doesn't match expected (512)"
    },
    {
      "implementation": "multihead_improved",
      "batch_size": 1,
      "seq_length": 1024,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 2.1768865175545216,
      "memory_mb": 57.15625,
      "throughput": 470396.59244632773,
      "success": true,
      "error": null
    },
    {
      "implementation": "multihead_improved",
      "batch_size": 1,
      "seq_length": 1024,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 0.0,
      "memory_mb": 0.0,
      "throughput": 0.0,
      "success": false,
      "error": "mat1 and mat2 shapes cannot be multiplied (1024x1024 and 512x1536)"
    },
    {
      "implementation": "multihead_improved",
      "batch_size": 1,
      "seq_length": 2048,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 7.3358784429728985,
      "memory_mb": 101.15625,
      "throughput": 279175.83639377187,
      "success": true,
      "error": null
    },
    {
      "implementation": "multihead_improved",
      "batch_size": 1,
      "seq_length": 2048,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 0.0,
      "memory_mb": 0.0,
      "throughput": 0.0,
      "success": false,
      "error": "mat1 and mat2 shapes cannot be multiplied (2048x1024 and 512x1536)"
    },
    {
      "implementation": "multihead_improved",
      "batch_size": 1,
      "seq_length": 4096,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 22.865020856261253,
      "memory_mb": 185.15625,
      "throughput": 179138.25776714174,
      "success": true,
      "error": null
    },
    {
      "implementation": "multihead_improved",
      "batch_size": 1,
      "seq_length": 4096,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 0.0,
      "memory_mb": 0.0,
      "throughput": 0.0,
      "success": false,
      "error": "mat1 and mat2 shapes cannot be multiplied (4096x1024 and 512x1536)"
    },
    {
      "implementation": "multihead_improved",
      "batch_size": 2,
      "seq_length": 1024,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 44.28803017362952,
      "memory_mb": 97.15625,
      "throughput": 46242.743061068526,
      "success": true,
      "error": null
    },
    {
      "implementation": "multihead_improved",
      "batch_size": 2,
      "seq_length": 1024,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 0.0,
      "memory_mb": 0.0,
      "throughput": 0.0,
      "success": false,
      "error": "mat1 and mat2 shapes cannot be multiplied (2048x1024 and 512x1536)"
    },
    {
      "implementation": "multihead_improved",
      "batch_size": 2,
      "seq_length": 2048,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 36.98704410344362,
      "memory_mb": 185.15625,
      "throughput": 110741.4798691266,
      "success": true,
      "error": null
    },
    {
      "implementation": "multihead_improved",
      "batch_size": 2,
      "seq_length": 2048,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 0.0,
      "memory_mb": 0.0,
      "throughput": 0.0,
      "success": false,
      "error": "mat1 and mat2 shapes cannot be multiplied (4096x1024 and 512x1536)"
    },
    {
      "implementation": "multihead_improved",
      "batch_size": 2,
      "seq_length": 4096,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 88.70292911306024,
      "memory_mb": 353.15625,
      "throughput": 92353.20729441218,
      "success": true,
      "error": null
    },
    {
      "implementation": "multihead_improved",
      "batch_size": 2,
      "seq_length": 4096,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 0.0,
      "memory_mb": 0.0,
      "throughput": 0.0,
      "success": false,
      "error": "mat1 and mat2 shapes cannot be multiplied (8192x1024 and 512x1536)"
    },
    {
      "implementation": "multihead_improved",
      "batch_size": 4,
      "seq_length": 1024,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 20.282649900764227,
      "memory_mb": 177.15625,
      "throughput": 201945.99916876087,
      "success": true,
      "error": null
    },
    {
      "implementation": "multihead_improved",
      "batch_size": 4,
      "seq_length": 1024,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 0.0,
      "memory_mb": 0.0,
      "throughput": 0.0,
      "success": false,
      "error": "mat1 and mat2 shapes cannot be multiplied (4096x1024 and 512x1536)"
    },
    {
      "implementation": "multihead_improved",
      "batch_size": 4,
      "seq_length": 2048,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 138.03644916042686,
      "memory_mb": 353.15625,
      "throughput": 59346.64394676803,
      "success": true,
      "error": null
    },
    {
      "implementation": "multihead_improved",
      "batch_size": 4,
      "seq_length": 2048,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 0.0,
      "memory_mb": 0.0,
      "throughput": 0.0,
      "success": false,
      "error": "mat1 and mat2 shapes cannot be multiplied (8192x1024 and 512x1536)"
    },
    {
      "implementation": "multihead_improved",
      "batch_size": 4,
      "seq_length": 4096,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 169.74183516576886,
      "memory_mb": 688.15625,
      "throughput": 96523.05210438832,
      "success": true,
      "error": null
    },
    {
      "implementation": "multihead_improved",
      "batch_size": 4,
      "seq_length": 4096,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 0.0,
      "memory_mb": 0.0,
      "throughput": 0.0,
      "success": false,
      "error": "mat1 and mat2 shapes cannot be multiplied (16384x1024 and 512x1536)"
    },
    {
      "implementation": "ring_v2",
      "batch_size": 1,
      "seq_length": 1024,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 3.531896695494652,
      "memory_mb": 96.15625,
      "throughput": 289929.20469792676,
      "success": true,
      "error": null
    },
    {
      "implementation": "ring_v2",
      "batch_size": 1,
      "seq_length": 1024,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 21.20282957330346,
      "memory_mb": 177.15625,
      "throughput": 48295.44077877799,
      "success": true,
      "error": null
    },
    {
      "implementation": "ring_v2",
      "batch_size": 1,
      "seq_length": 2048,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 23.040806595236063,
      "memory_mb": 305.15625,
      "throughput": 88885.77713349003,
      "success": true,
      "error": null
    },
    {
      "implementation": "ring_v2",
      "batch_size": 1,
      "seq_length": 2048,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 26.745736319571733,
      "memory_mb": 593.15625,
      "throughput": 76572.95262053917,
      "success": true,
      "error": null
    },
    {
      "implementation": "ring_v2",
      "batch_size": 1,
      "seq_length": 4096,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 36.032060626894236,
      "memory_mb": 1105.15625,
      "throughput": 113676.54052354576,
      "success": true,
      "error": null
    },
    {
      "implementation": "ring_v2",
      "batch_size": 1,
      "seq_length": 4096,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 212.7089286223054,
      "memory_mb": 2193.15625,
      "throughput": 19256.361387974568,
      "success": true,
      "error": null
    },
    {
      "implementation": "ring_v2",
      "batch_size": 2,
      "seq_length": 1024,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 14.03867481276393,
      "memory_mb": 181.15625,
      "throughput": 145882.71523591125,
      "success": true,
      "error": null
    },
    {
      "implementation": "ring_v2",
      "batch_size": 2,
      "seq_length": 1024,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 29.658242501318455,
      "memory_mb": 345.15625,
      "throughput": 69053.31628834568,
      "success": true,
      "error": null
    },
    {
      "implementation": "ring_v2",
      "batch_size": 2,
      "seq_length": 2048,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 39.670086186379194,
      "memory_mb": 601.15625,
      "throughput": 103251.60325480638,
      "success": true,
      "error": null
    },
    {
      "implementation": "ring_v2",
      "batch_size": 2,
      "seq_length": 2048,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 128.8129066117108,
      "memory_mb": 1185.15625,
      "throughput": 31798.05586055784,
      "success": true,
      "error": null
    },
    {
      "implementation": "ring_v2",
      "batch_size": 2,
      "seq_length": 4096,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 189.46864558383822,
      "memory_mb": 2209.15625,
      "throughput": 43236.705338536405,
      "success": true,
      "error": null
    },
    {
      "implementation": "ring_v2",
      "batch_size": 2,
      "seq_length": 4096,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 0.0,
      "memory_mb": 0.0,
      "throughput": 0.0,
      "success": false,
      "error": "CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacity of 7.88 GiB of which 1.35 GiB is free. Process 3093175 has 16.45 MiB memory in use. Including non-PyTorch memory, this process has 2.48 GiB memory in use. Of the allocated memory 2.23 GiB is allocated by PyTorch, and 125.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    {
      "implementation": "ring_v2",
      "batch_size": 4,
      "seq_length": 1024,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 24.278733599931,
      "memory_mb": 345.15625,
      "throughput": 168707.3167610209,
      "success": true,
      "error": null
    },
    {
      "implementation": "ring_v2",
      "batch_size": 4,
      "seq_length": 1024,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 20.405548065900803,
      "memory_mb": 673.15625,
      "throughput": 200729.72246429013,
      "success": true,
      "error": null
    },
    {
      "implementation": "ring_v2",
      "batch_size": 4,
      "seq_length": 2048,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 43.30357490107417,
      "memory_mb": 1185.15625,
      "throughput": 189176.0673042445,
      "success": true,
      "error": null
    },
    {
      "implementation": "ring_v2",
      "batch_size": 4,
      "seq_length": 2048,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 104.20545004308224,
      "memory_mb": 2352.15625,
      "throughput": 78613.93042890882,
      "success": true,
      "error": null
    },
    {
      "implementation": "ring_v2",
      "batch_size": 4,
      "seq_length": 4096,
      "num_heads": 8,
      "head_dim": 64,
      "time_ms": 0.0,
      "memory_mb": 0.0,
      "throughput": 0.0,
      "success": false,
      "error": "CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacity of 7.88 GiB of which 993.88 MiB is free. Process 3093175 has 16.45 MiB memory in use. Including non-PyTorch memory, this process has 2.86 GiB memory in use. Of the allocated memory 2.23 GiB is allocated by PyTorch, and 509.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    {
      "implementation": "ring_v2",
      "batch_size": 4,
      "seq_length": 4096,
      "num_heads": 16,
      "head_dim": 64,
      "time_ms": 0.0,
      "memory_mb": 0.0,
      "throughput": 0.0,
      "success": false,
      "error": "CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 7.88 GiB of which 2.97 GiB is free. Process 3093175 has 16.45 MiB memory in use. Including non-PyTorch memory, this process has 876.00 MiB memory in use. Of the allocated memory 592.16 MiB is allocated by PyTorch, and 157.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    }
  ],
  "timestamp": "20250630_095342"
}