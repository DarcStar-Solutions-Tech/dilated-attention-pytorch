[
  {
    "seq_len": 512,
    "batch_size": 2,
    "num_heads": 8,
    "head_dim": 64,
    "avg_time_ms": 1.6549110412597656,
    "std_time_ms": 0.7401071529205784,
    "min_time_ms": 1.1248588562011719,
    "max_time_ms": 3.6163330078125,
    "input_memory_mb": 3.0,
    "forward_memory_mb": 38.0,
    "peak_memory_mb": 57.12890625,
    "throughput_tokens_per_sec": 309382.18867054686,
    "has_nan": false,
    "has_inf": false,
    "output_mean": -2.9622176953125745e-05,
    "output_std": 0.0009025070467032492,
    "config_name": "Small",
    "world_size": 1,
    "segment_len": 256,
    "dilation_rate": 1
  },
  {
    "seq_len": 1024,
    "batch_size": 2,
    "num_heads": 8,
    "head_dim": 64,
    "avg_time_ms": 3.851437568664551,
    "std_time_ms": 0.6257872001698114,
    "min_time_ms": 3.306150436401367,
    "max_time_ms": 5.319118499755859,
    "input_memory_mb": 6.0,
    "forward_memory_mb": 108.0,
    "peak_memory_mb": 171.1328125,
    "throughput_tokens_per_sec": 265874.7498158362,
    "has_nan": false,
    "has_inf": false,
    "output_mean": 6.644186214543879e-06,
    "output_std": 0.0005574148381128907,
    "config_name": "Small+",
    "world_size": 1,
    "segment_len": 512,
    "dilation_rate": 1
  },
  {
    "seq_len": 2048,
    "batch_size": 2,
    "num_heads": 8,
    "head_dim": 64,
    "avg_time_ms": 16.014933586120605,
    "std_time_ms": 4.48206006263104,
    "min_time_ms": 12.323617935180664,
    "max_time_ms": 23.9715576171875,
    "input_memory_mb": 12.0,
    "forward_memory_mb": 308.0,
    "peak_memory_mb": 439.140625,
    "throughput_tokens_per_sec": 127880.6427130554,
    "has_nan": false,
    "has_inf": false,
    "output_mean": -6.057330665498739e-06,
    "output_std": 0.0003363190044183284,
    "config_name": "Medium",
    "world_size": 1,
    "segment_len": 1024,
    "dilation_rate": 1
  },
  {
    "seq_len": 4096,
    "batch_size": 1,
    "num_heads": 8,
    "head_dim": 64,
    "avg_time_ms": 84.23066139221191,
    "std_time_ms": 25.743048485423547,
    "min_time_ms": 50.644636154174805,
    "max_time_ms": 146.7893123626709,
    "input_memory_mb": 12.0,
    "forward_memory_mb": 572.0,
    "peak_memory_mb": 767.15625,
    "throughput_tokens_per_sec": 48628.372759978374,
    "has_nan": false,
    "has_inf": false,
    "output_mean": -5.094938842375996e-06,
    "output_std": 0.00019933251314796507,
    "config_name": "Large",
    "world_size": 1,
    "segment_len": 2048,
    "dilation_rate": 1
  },
  {
    "config_name": "XLarge",
    "seq_len": 8192,
    "error": "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacity of 7.88 GiB of which 730.31 MiB is free. Process 3093175 has 16.45 MiB memory in use. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 1.43 GiB is allocated by PyTorch, and 1.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
  },
  {
    "seq_len": 2048,
    "batch_size": 2,
    "num_heads": 8,
    "head_dim": 64,
    "avg_time_ms": 40.35804271697998,
    "std_time_ms": 24.165181571957866,
    "min_time_ms": 20.964384078979492,
    "max_time_ms": 95.95179557800293,
    "input_memory_mb": 12.0,
    "forward_memory_mb": 336.0,
    "peak_memory_mb": 783.140625,
    "throughput_tokens_per_sec": 50745.77115550596,
    "has_nan": false,
    "has_inf": false,
    "output_mean": 9.536553989164531e-06,
    "output_std": 0.0004656552628148347,
    "config_name": "Medium-Dilated",
    "world_size": 1,
    "segment_len": 512,
    "dilation_rate": 2
  },
  {
    "seq_len": 4096,
    "batch_size": 1,
    "num_heads": 8,
    "head_dim": 64,
    "avg_time_ms": 235.5212688446045,
    "std_time_ms": 305.19126772023856,
    "min_time_ms": 57.88373947143555,
    "max_time_ms": 1016.4148807525635,
    "input_memory_mb": 12.0,
    "forward_memory_mb": 572.0,
    "peak_memory_mb": 1111.15625,
    "throughput_tokens_per_sec": 17391.210654110884,
    "has_nan": false,
    "has_inf": false,
    "output_mean": 8.022433576115873e-06,
    "output_std": 0.00027283455710858107,
    "config_name": "Large-Dilated",
    "world_size": 1,
    "segment_len": 1024,
    "dilation_rate": 2
  }
]