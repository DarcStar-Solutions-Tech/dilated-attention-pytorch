--- a/dilated_attention_pytorch/ring_dilated_attention_hybrid.py
+++ b/dilated_attention_pytorch/ring_dilated_attention_hybrid.py
@@ -2,10 +2,13 @@
 Ring Dilated Attention Hybrid - True ring attention with production features.
 
 This implementation combines:
 - V3's true ring communication (O(n/p) memory scaling)
-- V2's dilation support and optimizations
+- V2's dilation support and optimizations 
 - V3's LSE accumulation for numerical stability
 - V2's memory pool, caching, and Flash Attention support
+
+IMPORTANT: Fixed to properly implement dilated attention by segmenting
+sequences first, then applying dilation within segments (not globally).
 """
 
 import math
@@ -350,6 +353,10 @@ class RingDilatedAttentionHybrid(nn.Module):
 
     def forward(
         self,
         q: Tensor,
         k: Tensor,
         v: Tensor,
         is_causal: bool = False,
     ) -> Tensor:
         """
         Forward pass using true ring attention with V2's features.
 
         Key: Uses ring passing (V3) instead of all_gather (V2) for true O(n/p) scaling.
+        Fixed: Now properly applies dilated attention within segments.
         """
         b, n, h, d = q.shape
 
         # Single device fallback
         if self.ring_size == 1:
             return self._single_device_forward(q, k, v, is_causal)
 
-        # Ensure sequence length is divisible by ring size
-        assert n % self.ring_size == 0, (
-            f"Sequence length {n} must be divisible by ring size {self.ring_size}"
-        )
-
-        # TRUE RING ATTENTION: Split K,V across ranks (V3 approach)
-        # Each GPU only stores 1/p of the K,V tensors
-        k_local = split_by_rank(k, self.rank, self.ring_size)
-        v_local = split_by_rank(v, self.rank, self.ring_size)
-
-        # CRITICAL: Apply dilation patterns BEFORE ring communication (V2 feature)
-        # This enables dilation > 1 in multi-GPU mode
-        k_local_dilated = self._apply_dilation_to_tensor(k_local)
-        v_local_dilated = self._apply_dilation_to_tensor(v_local)
-
-        # Apply dilation to full Q (needed for all chunks)
-        q_dilated = self._apply_dilation_to_tensor(q, is_query=True)
-
-        # Stack K,V for ring passing
-        kv_local = torch.stack((k_local_dilated, v_local_dilated))
+        # Use proper dilated attention with segmentation
+        return self._ring_forward_with_dilated_segments(q, k, v, is_causal)
+
+    def _ring_forward_with_dilated_segments(
+        self,
+        q: Tensor,
+        k: Tensor,
+        v: Tensor,
+        is_causal: bool,
+    ) -> Tensor:
+        """
+        Ring attention that properly handles dilated attention within segments.
+        
+        This is the key fix: We segment sequences and apply dilation within
+        segments during attention computation, not globally beforehand.
+        """
+        b, n, h, d = q.shape
+        
+        # Ensure divisibility
+        assert n % self.ring_size == 0, (
+            f"Sequence length {n} must be divisible by ring size {self.ring_size}"
+        )
+        
+        # Split K,V across GPUs (standard ring attention)
+        chunk_size = n // self.ring_size
+        k_local = split_by_rank(k, self.rank, self.ring_size)
+        v_local = split_by_rank(v, self.rank, self.ring_size)
+        
+        # Stack for ring passing (NO dilation applied yet!)
+        kv_local = torch.stack((k_local, v_local))
 
         # Pre-allocate receive buffer if needed
         if (
             self._kv_receive_buffer is None
             or self._kv_receive_buffer.shape != kv_local.shape
         ):
             self._kv_receive_buffer = torch.empty_like(kv_local)
 
         # Initialize LSE accumulator (V3's numerical stability)
         accumulator = StableRingAccumulator(
             output_shape=(b, h, n, d),  # Note: heads before seq for LSE
             device=q.device,
             dtype=q.dtype,
         )
 
-        # Transpose Q for attention computation
-        q_transposed = q_dilated.transpose(1, 2)  # (b, h, n, d)
-
         # TRUE RING ATTENTION: Pass K,V chunks around the ring
         # This is the key difference from V2 which uses all_gather
         ring_pass_fn = partial(
             all_ring_pass,
             receive_buffer=self._kv_receive_buffer,
             ring_size=self.ring_size,
         )
 
         # Process each ring position
         for ring_info, (kv_chunk,) in ring_pass_fn(kv_local):
             if not exists(kv_chunk):
                 continue
 
             k_chunk, v_chunk = kv_chunk
-
-            # Calculate chunk position in global sequence
-            chunk_size = n // self.ring_size
             chunk_idx = ring_info.ring_rank
             chunk_start = chunk_idx * chunk_size
 
-            # Compute attention for this chunk
-            chunk_output, chunk_lse = self._compute_chunk_attention(
-                q_transposed,
+            # Compute dilated attention for this chunk
+            chunk_output, chunk_lse = self._compute_dilated_chunk_attention(
+                q,
                 k_chunk,
                 v_chunk,
                 chunk_start,
                 chunk_size,
                 is_causal,
-                ring_info,
             )
 
             # Accumulate with LSE
             accumulator.update(chunk_output, chunk_lse)
 
         # Get final output and transpose back
         output = accumulator.get_output().transpose(1, 2)  # (b, n, h, d)
 
         return output
+        
+    def _compute_dilated_chunk_attention(
+        self,
+        q: Tensor,  # (b, n, h, d) - full Q
+        k_chunk: Tensor,  # (b, chunk_size, h, d) - chunk of K
+        v_chunk: Tensor,  # (b, chunk_size, h, d) - chunk of V
+        chunk_start: int,
+        chunk_size: int,
+        is_causal: bool,
+    ) -> Tuple[Tensor, Tensor]:
+        """
+        Compute attention with proper dilated attention semantics.
+        
+        This is the key fix: We segment the sequences and apply
+        dilation within segments, not globally.
+        """
+        b, n, h, d = q.shape
+        
+        # Transpose to attention format
+        q_t = q.transpose(1, 2)  # (b, h, n, d)
+        k_chunk_t = k_chunk.transpose(1, 2)  # (b, h, chunk_size, d)
+        v_chunk_t = v_chunk.transpose(1, 2)  # (b, h, chunk_size, d)
+        
+        # Calculate head groups
+        heads_per_group = self._calculate_head_groups(h)
+        
+        # Pre-allocate output
+        output = torch.zeros(b, h, n, d, device=q.device, dtype=q.dtype)
+        lse = torch.full((b, h, n), float('-inf'), device=q.device, dtype=q.dtype)
+        
+        # Process each head group with its segment configuration
+        head_start = 0
+        for i, (segment_len, dilation_rate, group_size) in enumerate(
+            zip(self.segment_lengths, self.dilation_rates, heads_per_group)
+        ):
+            if group_size == 0:
+                continue
+                
+            head_end = head_start + group_size
+            
+            # Process this head group with proper segmentation
+            group_output, group_lse = self._process_head_group_segments(
+                q_t[:, head_start:head_end],  # Q for this head group
+                k_chunk_t[:, head_start:head_end],  # K chunk for this head group
+                v_chunk_t[:, head_start:head_end],  # V chunk for this head group
+                segment_len,
+                dilation_rate,
+                i,  # offset index
+                chunk_start,
+                chunk_size,
+                is_causal,
+            )
+            
+            output[:, head_start:head_end] = group_output
+            lse[:, head_start:head_end] = group_lse
+            
+            head_start = head_end
+            
+        return output, lse
+        
+    def _process_head_group_segments(
+        self,
+        q_group: Tensor,  # (b, group_heads, n, d)
+        k_chunk_group: Tensor,  # (b, group_heads, chunk_size, d)
+        v_chunk_group: Tensor,  # (b, group_heads, chunk_size, d)
+        segment_len: int,
+        dilation_rate: int,
+        offset_idx: int,
+        chunk_start: int,
+        chunk_size: int,
+        is_causal: bool,
+    ) -> Tuple[Tensor, Tensor]:
+        """
+        Process segments with dilation for a head group.
+        
+        This implements the correct algorithm:
+        1. Determine which segments overlap with this chunk
+        2. For each segment, apply dilation and compute attention
+        """
+        b, gh, n, d = q_group.shape
+        
+        # Initialize output for this head group
+        output = torch.zeros_like(q_group)
+        lse = torch.full((b, gh, n), float('-inf'), device=q_group.device)
+        
+        # Determine segment boundaries
+        num_segments = (n + segment_len - 1) // segment_len
+        
+        # Process each segment
+        for seg_idx in range(num_segments):
+            seg_start = seg_idx * segment_len
+            seg_end = min(seg_start + segment_len, n)
+            actual_seg_len = seg_end - seg_start
+            
+            # Check if this segment overlaps with the current chunk
+            if seg_end <= chunk_start or seg_start >= chunk_start + chunk_size:
+                continue  # No overlap
+                
+            # Determine overlap region
+            overlap_start = max(seg_start, chunk_start)
+            overlap_end = min(seg_end, chunk_start + chunk_size)
+            
+            # Get Q for this segment
+            q_seg = q_group[:, :, seg_start:seg_end, :]
+            
+            # Get K,V from chunk that corresponds to this segment's overlap
+            k_overlap_start = overlap_start - chunk_start
+            k_overlap_end = overlap_end - chunk_start
+            k_seg = k_chunk_group[:, :, k_overlap_start:k_overlap_end, :]
+            v_seg = v_chunk_group[:, :, k_overlap_start:k_overlap_end, :]
+            
+            # Apply dilation within segment
+            if dilation_rate > 1:
+                # Calculate offset for this segment
+                offset = (offset_idx + seg_idx) % dilation_rate
+                
+                # Get dilation pattern for segment
+                pattern = self._get_segment_dilation_pattern(
+                    actual_seg_len, dilation_rate, offset
+                )
+                
+                # Apply dilation to Q (segment-local indices)
+                q_seg_dilated = q_seg.index_select(2, pattern)
+                
+                # For K,V we need to map the pattern to chunk-local indices
+                overlap_len = overlap_end - overlap_start
+                k_pattern = self._map_pattern_to_overlap(
+                    pattern, seg_start, overlap_start, overlap_len
+                )
+                
+                if k_pattern is not None and len(k_pattern) > 0:
+                    k_seg_dilated = k_seg.index_select(2, k_pattern)
+                    v_seg_dilated = v_seg.index_select(2, k_pattern)
+                else:
+                    continue  # No valid positions in this chunk
+            else:
+                q_seg_dilated = q_seg
+                k_seg_dilated = k_seg
+                v_seg_dilated = v_seg
+                
+            # Compute attention for this dilated segment
+            seg_output, seg_lse = self._compute_segment_attention(
+                q_seg_dilated,
+                k_seg_dilated,
+                v_seg_dilated,
+                seg_start,
+                overlap_start,
+                is_causal,
+            )
+            
+            # Map output back to full positions
+            if dilation_rate > 1:
+                # Place dilated output back in correct positions
+                for i, idx in enumerate(pattern):
+                    if seg_start + idx < n:
+                        output[:, :, seg_start + idx, :] = seg_output[:, :, i, :]
+                        lse[:, :, seg_start + idx] = seg_lse[:, :, i]
+            else:
+                output[:, :, seg_start:seg_end, :] = seg_output
+                lse[:, :, seg_start:seg_end] = seg_lse
+                
+        return output, lse
+        
+    def _get_segment_dilation_pattern(
+        self, seg_len: int, dilation_rate: int, offset: int
+    ) -> Tensor:
+        """Get dilation pattern for a segment."""
+        cache_key = (seg_len, dilation_rate, offset)
+        
+        if cache_key in self._dilation_pattern_cache:
+            return self._dilation_pattern_cache[cache_key]
+            
+        # Create pattern for segment
+        indices = []
+        for i in range(0, seg_len, dilation_rate):
+            idx = (i + offset) % seg_len
+            if idx < seg_len:
+                indices.append(idx)
+                
+        # Ensure we have enough indices
+        if len(indices) < seg_len // dilation_rate:
+            # Cycle through to fill
+            cycle_len = len(indices)
+            while len(indices) < seg_len:
+                for i in range(cycle_len):
+                    if len(indices) < seg_len:
+                        indices.append(indices[i])
+                        
+        pattern = torch.tensor(indices, device=self.device, dtype=torch.long)
+        self._dilation_pattern_cache[cache_key] = pattern
+        
+        return pattern
+        
+    def _map_pattern_to_overlap(
+        self,
+        pattern: Tensor,
+        seg_start: int,
+        overlap_start: int,
+        overlap_len: int,
+    ) -> Optional[Tensor]:
+        """Map segment-local pattern to chunk-local indices."""
+        # Filter pattern to only include positions in overlap
+        valid_indices = []
+        
+        for idx in pattern:
+            global_pos = seg_start + idx
+            if overlap_start <= global_pos < overlap_start + overlap_len:
+                chunk_local_idx = global_pos - overlap_start
+                valid_indices.append(chunk_local_idx)
+                
+        if not valid_indices:
+            return None
+            
+        return torch.tensor(valid_indices, device=pattern.device, dtype=torch.long)
+        
+    def _compute_segment_attention(
+        self,
+        q_seg: Tensor,  # (b, h, seg_len_dilated, d)
+        k_seg: Tensor,  # (b, h, overlap_len_dilated, d)
+        v_seg: Tensor,  # (b, h, overlap_len_dilated, d)
+        seg_start: int,
+        overlap_start: int,
+        is_causal: bool,
+    ) -> Tuple[Tensor, Tensor]:
+        """Compute attention for a dilated segment."""
+        # Try Flash Attention if available
+        if self._can_use_flash and not self._skip_flash_attempt:
+            try:
+                # Transpose for Flash
+                q_flash = q_seg.transpose(1, 2)  # (b, seg_len, h, d)
+                k_flash = k_seg.transpose(1, 2)
+                v_flash = v_seg.transpose(1, 2)
+                
+                output = flash_attention_forward(
+                    q_flash, k_flash, v_flash,
+                    dropout_p=self.dropout if self.training else 0.0,
+                    is_causal=is_causal and seg_start == 0,
+                    backend=self.flash_backend,
+                )
+                
+                # Compute LSE separately for accumulation
+                scores = torch.matmul(q_seg, k_seg.transpose(-2, -1)) / math.sqrt(
+                    q_seg.shape[-1]
+                )
+                if is_causal:
+                    # Apply causal mask properly for segment
+                    q_len, k_len = q_seg.shape[2], k_seg.shape[2]
+                    for i in range(q_len):
+                        for j in range(k_len):
+                            if seg_start + i < overlap_start + j:
+                                scores[:, :, i, j] = float('-inf')
+                                
+                lse = scores.logsumexp(dim=-1)
+                return output.transpose(1, 2), lse
+                
+            except Exception:
+                pass  # Fall through to standard
+                
+        # Standard attention computation with LSE
+        return compute_attention_with_lse(
+            q_seg, k_seg, v_seg,
+            scale=1.0 / math.sqrt(q_seg.shape[-1]),
+            mask=self._get_segment_causal_mask(
+                q_seg.shape[2], k_seg.shape[2], seg_start, overlap_start, is_causal
+            ),
+            dropout=self.dropout,
+            training=self.training,
+        )
+        
+    def _get_segment_causal_mask(
+        self,
+        q_len: int,
+        k_len: int,
+        seg_start: int,
+        overlap_start: int,
+        is_causal: bool,
+    ) -> Optional[Tensor]:
+        """Get causal mask for segment attention."""
+        if not is_causal:
+            return None
+            
+        mask = torch.ones(q_len, k_len, device=self.device, dtype=torch.bool)
+        
+        for i in range(q_len):
+            for j in range(k_len):
+                q_pos = seg_start + i
+                k_pos = overlap_start + j
+                if q_pos < k_pos:
+                    mask[i, j] = False
+                    
+        return mask
 
-    def _compute_chunk_attention(
-        self,
-        q: Tensor,  # (b, h, n, d) - full Q
-        k_chunk: Tensor,  # (b, chunk_size, h, d) - chunk of K
-        v_chunk: Tensor,  # (b, chunk_size, h, d) - chunk of V
-        chunk_start: int,
-        chunk_size: int,
-        is_causal: bool,
-        ring_info: RingInfo,
-    ) -> Tuple[Tensor, Tensor]:
-        """Compute attention for one chunk with V2's optimizations."""
-        # Transpose K,V chunks to attention format
-        k_chunk = k_chunk.transpose(1, 2)  # (b, h, chunk_size, d)
-        v_chunk = v_chunk.transpose(1, 2)  # (b, h, chunk_size, d)
-
-        # Try Flash Attention first (V2 optimization)
-        if self._can_use_flash and not self._skip_flash_attempt:
-            try:
-                # Adjust causal for chunk
-                adjusted_causal = is_causal and chunk_start == 0
-
-                # Use Flash Attention
-                output = flash_attention_forward(
-                    q.transpose(1, 2),  # Flash expects (b, n, h, d)
-                    k_chunk.transpose(1, 2),
-                    v_chunk.transpose(1, 2),
-                    dropout_p=self.dropout if self.training else 0.0,
-                    is_causal=adjusted_causal,
-                    backend=self.flash_backend,
-                )
-
-                # Compute LSE separately for accumulation
-                # This is a limitation but necessary for ring accumulation
-                scores = torch.matmul(q, k_chunk.transpose(-2, -1)) / math.sqrt(
-                    q.shape[-1]
-                )
-                if is_causal:
-                    mask = self._get_causal_mask(q.shape[2], chunk_size, chunk_start)
-                    scores.masked_fill_(~mask.unsqueeze(0).unsqueeze(0), float("-inf"))
-
-                lse = scores.logsumexp(dim=-1, keepdim=True).squeeze(-1)
-
-                return output.transpose(1, 2), lse
-
-            except Exception:
-                pass  # Fall through to standard computation
-
-        # Standard computation with LSE (V3 approach)
-        mask = None
-        if is_causal:
-            mask = self._get_causal_mask(q.shape[2], chunk_size, chunk_start)
-
-        output, lse = compute_attention_with_lse(
-            q,
-            k_chunk,
-            v_chunk,
-            scale=1.0 / math.sqrt(q.shape[-1]),
-            mask=mask,
-            dropout=self.dropout,
-            training=self.training,
-        )
-
-        return output, lse
-
     def _single_device_forward(
         self,
         q: Tensor,
         k: Tensor,
         v: Tensor,
         is_causal: bool,
     ) -> Tensor:
-        """Single device forward with dilation patterns."""
-        # Apply dilation patterns
-        q_dilated = self._apply_dilation_to_tensor(q, is_query=True)
-        k_dilated = self._apply_dilation_to_tensor(k)
-        v_dilated = self._apply_dilation_to_tensor(v)
-
-        # Use Flash Attention if available
-        if self._can_use_flash:
-            try:
-                output = flash_attention_forward(
-                    q_dilated,
-                    k_dilated,
-                    v_dilated,
-                    dropout_p=self.dropout if self.training else 0.0,
-                    is_causal=is_causal,
-                    backend=self.flash_backend,
-                )
-                return output
-            except Exception:
-                pass
-
-        # Fall back to standard attention
-        q_t = q_dilated.transpose(1, 2)
-        k_t = k_dilated.transpose(1, 2)
-        v_t = v_dilated.transpose(1, 2)
-
-        # Compute attention
-        scores = torch.matmul(q_t, k_t.transpose(-2, -1)) / math.sqrt(q.shape[-1])
-
-        if is_causal:
-            causal_mask = torch.triu(
-                torch.ones(q.shape[1], k.shape[1], device=q.device), diagonal=1
-            ).bool()
-            scores.masked_fill_(causal_mask.unsqueeze(0).unsqueeze(0), float("-inf"))
-
-        attn_weights = F.softmax(scores, dim=-1)
-
-        if self.training and self.dropout > 0:
-            attn_weights = F.dropout(attn_weights, p=self.dropout)
-
-        output = torch.matmul(attn_weights, v_t)
-        return output.transpose(1, 2)
+        """Single device forward with proper dilated attention."""
+        b, n, h, d = q.shape
+        
+        # Transpose to attention format
+        q_t = q.transpose(1, 2)  # (b, h, n, d)
+        k_t = k.transpose(1, 2)
+        v_t = v.transpose(1, 2)
+        
+        # Calculate head groups
+        heads_per_group = self._calculate_head_groups(h)
+        
+        # Process each head group
+        output = torch.zeros_like(q_t)
+        head_start = 0
+        
+        for i, (segment_len, dilation_rate, group_size) in enumerate(
+            zip(self.segment_lengths, self.dilation_rates, heads_per_group)
+        ):
+            if group_size == 0:
+                continue
+                
+            head_end = head_start + group_size
+            
+            # Process segments for this head group
+            group_output = self._process_single_device_segments(
+                q_t[:, head_start:head_end],
+                k_t[:, head_start:head_end],
+                v_t[:, head_start:head_end],
+                segment_len,
+                dilation_rate,
+                i,  # offset index
+                is_causal,
+            )
+            
+            output[:, head_start:head_end] = group_output
+            head_start = head_end
+            
+        return output.transpose(1, 2)  # (b, n, h, d)
+        
+    def _process_single_device_segments(
+        self,
+        q_group: Tensor,
+        k_group: Tensor,
+        v_group: Tensor,
+        segment_len: int,
+        dilation_rate: int,
+        offset_idx: int,
+        is_causal: bool,
+    ) -> Tensor:
+        """Process segments on single device with proper dilation."""
+        b, gh, n, d = q_group.shape
+        output = torch.zeros_like(q_group)
+        
+        # Process each segment
+        num_segments = (n + segment_len - 1) // segment_len
+        
+        for seg_idx in range(num_segments):
+            seg_start = seg_idx * segment_len
+            seg_end = min(seg_start + segment_len, n)
+            actual_seg_len = seg_end - seg_start
+            
+            # Get segment
+            q_seg = q_group[:, :, seg_start:seg_end, :]
+            k_seg = k_group[:, :, seg_start:seg_end, :]
+            v_seg = v_group[:, :, seg_start:seg_end, :]
+            
+            # Apply dilation within segment
+            if dilation_rate > 1:
+                offset = (offset_idx + seg_idx) % dilation_rate
+                pattern = self._get_segment_dilation_pattern(
+                    actual_seg_len, dilation_rate, offset
+                )
+                
+                q_seg = q_seg.index_select(2, pattern)
+                k_seg = k_seg.index_select(2, pattern)
+                v_seg = v_seg.index_select(2, pattern)
+                
+            # Compute attention for segment
+            seg_output, _ = compute_attention_with_lse(
+                q_seg, k_seg, v_seg,
+                scale=1.0 / math.sqrt(d),
+                mask=self._get_segment_causal_mask(
+                    q_seg.shape[2], k_seg.shape[2], seg_start, seg_start, is_causal
+                ),
+                dropout=self.dropout,
+                training=self.training,
+            )
+            
+            # Place output back
+            if dilation_rate > 1:
+                for i, idx in enumerate(pattern):
+                    if seg_start + idx < n:
+                        output[:, :, seg_start + idx, :] = seg_output[:, :, i, :]
+            else:
+                output[:, :, seg_start:seg_end, :] = seg_output
+                
+        return output


 # Alias for compatibility
 RingDilatedAttentionTrue = RingDilatedAttentionHybrid